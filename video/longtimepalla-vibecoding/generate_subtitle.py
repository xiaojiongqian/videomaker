#!/usr/bin/env python3
"""
é«˜è´¨é‡å­—å¹•ç”Ÿæˆ
æ”¯æŒ FunASR (ä¼˜å…ˆ) å’Œ Whisper (å¤‡ç”¨)
ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ LLM ä¼˜åŒ–
"""

import os
import subprocess
import json
import tempfile
import sys

# ==================== é…ç½® ====================

VIDEO_FILE = "video_final_4k.mp4"
OUTPUT_SRT = "video_final_4k.srt"

# å°è¯•ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒçš„ Python
VENV_PYTHON = os.path.join(os.path.dirname(os.path.abspath(__file__)), "venv", "bin", "python3")
SYSTEM_PYTHON = "python3"

# æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
if os.path.exists(VENV_PYTHON):
    PYTHON_CMD = VENV_PYTHON
    print(f"ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ Python: {PYTHON_CMD}")
else:
    PYTHON_CMD = SYSTEM_PYTHON
    print(f"ä½¿ç”¨ç³»ç»Ÿ Python: {PYTHON_CMD}")

# ==================== æ­¥éª¤ 1: æå–éŸ³é¢‘ ====================

def extract_audio(video_path, audio_path):
    """æå–éŸ³é¢‘"""
    print("ğŸµ æå–éŸ³é¢‘...")
    cmd = [
        'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
        '-i', video_path, '-vn', '-acodec', 'pcm_s16le',
        '-ar', '16000', '-ac', '1', audio_path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode == 0:
        print(f"   âœ… å®Œæˆ")
        return True
    return False

# ==================== æ­¥éª¤ 2: ASR è¯†åˆ« ====================

def transcribe_with_funasr(audio_path, output_json):
    """ä½¿ç”¨ FunASR è¯†åˆ«"""
    print("\nğŸ¤ å°è¯• FunASR è¯†åˆ«...")
    
    funasr_script = f'''
import json
import os
import sys

os.environ["MODELSCOPE_CACHE"] = "{os.path.dirname(audio_path)}"

try:
    from funasr import AutoModel
    
    print("åŠ è½½ FunASR æ¨¡å‹...")
    model = AutoModel(
        model="paraformer-zh",
        vad_model="fsmn-vad",
        punc_model="ct-punc",
    )
    
    print("å¼€å§‹è¯†åˆ«...")
    result = model.generate(input="{audio_path}")
    
    with open("{output_json}", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("âœ… FunASR è¯†åˆ«å®Œæˆ")
    
except Exception as e:
    print(f"âŒ FunASR å¤±è´¥: {{e}}")
    sys.exit(1)
'''
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(funasr_script)
        script_path = f.name
    
    try:
        result = subprocess.run(
            [PYTHON_CMD, script_path],
            capture_output=True, text=True, timeout=300
        )
        os.unlink(script_path)
        
        if result.returncode == 0 and os.path.exists(output_json):
            print(f"   âœ… FunASR æˆåŠŸ")
            return True, "funasr"
        else:
            print(f"   âš ï¸  FunASR å¤±è´¥: {result.stderr[:200]}")
            return False, None
    except Exception as e:
        os.unlink(script_path)
        print(f"   âš ï¸  FunASR é”™è¯¯: {e}")
        return False, None

def transcribe_with_whisper(audio_path, output_json):
    """ä½¿ç”¨ Whisper è¯†åˆ«ï¼ˆå¤‡ç”¨ï¼‰"""
    print("\nğŸ¤ ä½¿ç”¨ Whisper è¯†åˆ«...")
    
    cmd = [
        'whisper', audio_path,
        '--model', 'base',
        '--language', 'zh',
        '--output_format', 'json',
        '--output_dir', os.path.dirname(output_json),
        '--fp16', 'False'
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
    
    if result.returncode == 0:
        base_name = os.path.splitext(os.path.basename(audio_path))[0]
        whisper_json = os.path.join(os.path.dirname(output_json), f"{base_name}.json")
        if os.path.exists(whisper_json):
            os.rename(whisper_json, output_json)
            print(f"   âœ… Whisper æˆåŠŸ")
            return True
    
    print(f"   âŒ Whisper å¤±è´¥")
    return False

# ==================== æ­¥éª¤ 3: åŠ è½½ç»“æœ ====================

def load_asr_result(json_path, asr_type):
    """åŠ è½½ ASR ç»“æœ"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    segments = []
    
    if asr_type == "funasr":
        # FunASR æ ¼å¼
        if isinstance(data, list) and len(data) > 0:
            for item in data:
                if isinstance(item, dict):
                    text = item.get('text', '')
                    timestamp = item.get('timestamp', [])
                    if text and timestamp:
                        segments.append({
                            'start': timestamp[0][0] / 1000,
                            'end': timestamp[-1][1] / 1000,
                            'text': text
                        })
    else:
        # Whisper æ ¼å¼
        segments = data.get('segments', [])
        segments = [{'start': s['start'], 'end': s['end'], 'text': s['text']} for s in segments]
    
    return segments

# ==================== æ­¥éª¤ 4: åˆå¹¶çŸ­ç‰‡æ®µ ====================

def merge_segments(segments, min_duration=1.5, max_gap=0.3):
    """åˆå¹¶çŸ­ç‰‡æ®µ"""
    if not segments:
        return []
    
    merged = []
    current = {
        'start': segments[0]['start'],
        'end': segments[0]['end'],
        'text': segments[0]['text'].strip()
    }
    
    for seg in segments[1:]:
        gap = seg['start'] - current['end']
        duration = current['end'] - current['start']
        
        if gap < max_gap and duration < min_duration:
            current['end'] = seg['end']
            current['text'] += ' ' + seg['text'].strip()
        else:
            merged.append(current)
            current = {
                'start': seg['start'],
                'end': seg['end'],
                'text': seg['text'].strip()
            }
    
    merged.append(current)
    return merged

# ==================== æ­¥éª¤ 5: ä¸Šä¸‹æ–‡æ„ŸçŸ¥ LLM ä¼˜åŒ– ====================

def create_paragraphs(segments, max_duration=45, max_gap=2.0):
    """å°†ç‰‡æ®µç»„åˆæˆæ®µè½"""
    if not segments:
        return []
    
    paragraphs = []
    current = {
        'start': segments[0]['start'],
        'end': segments[0]['end'],
        'texts': [segments[0]['text']],
        'segments': [segments[0]]
    }
    
    for seg in segments[1:]:
        gap = seg['start'] - current['end']
        duration = current['end'] - current['start']
        
        if gap < max_gap and duration < max_duration:
            current['end'] = seg['end']
            current['texts'].append(seg['text'])
            current['segments'].append(seg)
        else:
            paragraphs.append(current)
            current = {
                'start': seg['start'],
                'end': seg['end'],
                'texts': [seg['text']],
                'segments': [seg]
            }
    
    paragraphs.append(current)
    return paragraphs

def optimize_paragraph_with_context(para, prev_para, next_para):
    """ä½¿ç”¨ LLM åŸºäºä¸Šä¸‹æ–‡ä¼˜åŒ–æ®µè½"""
    
    # æ„å»ºä¸Šä¸‹æ–‡
    prev_text = ' '.join(prev_para['texts'])[-80:] if prev_para else ""
    next_text = ' '.join(next_para['texts'])[:80] if next_para else ""
    current_text = ' '.join(para['texts'])
    
    prompt = f"""ä½œä¸ºä¸“ä¸šå­—å¹•æ ¡å¯¹ä¸“å®¶ï¼Œè¯·åŸºäºä¸Šä¸‹æ–‡ä¼˜åŒ–ä»¥ä¸‹å­—å¹•æ–‡æœ¬ã€‚

ã€å‰æ–‡ã€‘{prev_text}

ã€å½“å‰æ–‡æœ¬ã€‘{current_text}

ã€åæ–‡ã€‘{next_text}

ã€ä¼˜åŒ–è¦æ±‚ã€‘
1. åŸºäºä¸Šä¸‹æ–‡ç†è§£ä¿®æ­£è¯†åˆ«é”™è¯¯ï¼ˆç»“åˆå‰åæ–‡è¯­ä¹‰ï¼‰
2. ç»Ÿä¸€æŠ€æœ¯æœ¯è¯­ï¼š
   - "Codex/CC/å…‹åŠ³å¾·ä»£ç " â†’ "Claude Code"
   - "Vibe Coding" â†’ ä¿æŒåŸæ ·
   - "Full Access Mode" â†’ ä¿æŒåŸæ ·
   - "Worktree/å·¥ä½œæ ‘" â†’ "Git Worktree"
   - "MCP/mcp" â†’ "MCP"
3. ä¿æŒå¥å­åœ¨ä¸Šä¸‹æ–‡ä¸­é€šé¡ºè¿è´¯
4. åˆ é™¤é‡å¤è¯ã€å£å¤´ç¦…ã€è¯­æ°”è¯
5. æ ¹æ®è¯­æ°”æ·»åŠ åˆé€‚çš„æ ‡ç‚¹ç¬¦å·
6. ä¸è¦æ”¹å˜åŸæ„ï¼Œä¸è¦æ·»åŠ åŸæ–‡æ²¡æœ‰çš„å†…å®¹

ã€é‡è¦ã€‘ç›´æ¥è¿”å›ä¼˜åŒ–åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ è§£é‡Šã€‚"""

    try:
        result = subprocess.run(
            ['kimi', '-c', prompt],
            capture_output=True, text=True, timeout=90
        )
        
        if result.returncode == 0:
            optimized = result.stdout.strip()
            # æ¸…ç†å¯èƒ½çš„å¼•å·å’Œè¯´æ˜
            optimized = optimized.strip('"').strip("'")
            # å»é™¤ "ä¼˜åŒ–åæ–‡æœ¬:" ç­‰å‰ç¼€
            if ':' in optimized[:20]:
                optimized = optimized.split(':', 1)[1].strip()
            return optimized
        
    except Exception as e:
        print(f"   LLM é”™è¯¯: {e}")
    
    return None

def distribute_optimized_text(para, optimized_text):
    """å°†ä¼˜åŒ–åçš„æ–‡æœ¬åˆ†é…åˆ°å„ä¸ªç‰‡æ®µ"""
    segments = para['segments']
    original_texts = para['texts']
    
    if len(segments) == 1:
        return [{'start': segments[0]['start'], 'end': segments[0]['end'], 
                'text': optimized_text, 'original': segments[0]['text']}]
    
    # æŒ‰æ¯”ä¾‹åˆ†é…
    original_total = sum(len(t) for t in original_texts)
    result = []
    current_pos = 0
    
    for i, seg in enumerate(segments):
        if i == len(segments) - 1:
            # æœ€åä¸€ä¸ªç‰‡æ®µå–å‰©ä½™æ‰€æœ‰
            seg_text = optimized_text[current_pos:]
        else:
            # æŒ‰æ¯”ä¾‹è®¡ç®—
            ratio = len(original_texts[i]) / original_total
            seg_len = int(len(optimized_text) * ratio)
            seg_text = optimized_text[current_pos:current_pos + seg_len]
            current_pos += seg_len
        
        result.append({
            'start': seg['start'],
            'end': seg['end'],
            'text': seg_text.strip(),
            'original': seg['text']
        })
    
    return result

def contextual_llm_optimize(segments):
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥ LLM ä¼˜åŒ–"""
    print("\nğŸ¤– ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¼˜åŒ–...")
    
    # ç»„åˆæˆæ®µè½
    paragraphs = create_paragraphs(segments)
    print(f"   ç»„åˆæˆ {len(paragraphs)} ä¸ªæ®µè½")
    
    optimized_segments = []
    
    for i, para in enumerate(paragraphs):
        print(f"   æ®µè½ {i+1}/{len(paragraphs)}...", end=" ", flush=True)
        
        # è·å–ä¸Šä¸‹æ–‡
        prev_para = paragraphs[i-1] if i > 0 else None
        next_para = paragraphs[i+1] if i < len(paragraphs)-1 else None
        
        # LLM ä¼˜åŒ–
        optimized_text = optimize_paragraph_with_context(para, prev_para, next_para)
        
        if optimized_text:
            # åˆ†é…ä¼˜åŒ–åçš„æ–‡æœ¬åˆ°å„ä¸ªç‰‡æ®µ
            segs = distribute_optimized_text(para, optimized_text)
            optimized_segments.extend(segs)
            print("âœ“")
        else:
            # ä½¿ç”¨åŸæ–‡
            for seg in para['segments']:
                optimized_segments.append({
                    'start': seg['start'],
                    'end': seg['end'],
                    'text': seg['text'],
                    'original': seg['text']
                })
            print("â—‹(åŸæ–‡)")
    
    print(f"   âœ… ä¼˜åŒ–å®Œæˆ: {len(optimized_segments)} æ¡")
    return optimized_segments

# ==================== æ­¥éª¤ 6: ç”Ÿæˆ SRT ====================

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def generate_srt(segments, output_path):
    """ç”Ÿæˆ SRT"""
    print(f"\nğŸ“ ç”Ÿæˆ SRT...")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        idx = 1
        for seg in segments:
            text = seg['text'].strip()
            if not text:
                continue
            
            start = format_time(seg['start'])
            end = format_time(seg['end'])
            
            # é•¿æ–‡æœ¬æ¢è¡Œ
            if len(text) > 30:
                mid = len(text) // 2
                for j in range(mid, min(mid+15, len(text))):
                    if text[j] in 'ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼,':
                        text = text[:j+1] + '\n' + text[j+1:]
                        break
            
            f.write(f"{idx}\n{start} --> {end}\n{text}\n\n")
            idx += 1
    
    size = os.path.getsize(output_path) / 1024
    print(f"   âœ… å·²ç”Ÿæˆ: {output_path} ({size:.1f}KB)")

def show_comparison(segments):
    """æ˜¾ç¤ºå¯¹æ¯”"""
    print(f"\nğŸ“‹ ä¼˜åŒ–å¯¹æ¯” (å‰5æ¡):")
    print("-" * 70)
    for seg in segments[:5]:
        orig = seg.get('original', seg['text'])[:40]
        text = seg['text'][:40]
        print(f"åŸæ–‡: {orig}")
        print(f"ä¼˜åŒ–: {text}")
        print()

# ==================== ä¸»ç¨‹åº ====================

def main():
    print("=" * 70)
    print("ğŸ¬ å­—å¹•ç”Ÿæˆ: FunASR/Whisper + ä¸Šä¸‹æ–‡æ„ŸçŸ¥ LLM ä¼˜åŒ–")
    print("=" * 70)
    
    if not os.path.exists(VIDEO_FILE):
        print(f"âŒ è§†é¢‘ä¸å­˜åœ¨: {VIDEO_FILE}")
        return
    
    with tempfile.TemporaryDirectory() as temp_dir:
        audio_path = os.path.join(temp_dir, "audio.wav")
        json_path = os.path.join(temp_dir, "asr_result.json")
        
        # 1. æå–éŸ³é¢‘
        if not extract_audio(VIDEO_FILE, audio_path):
            return
        
        # 2. ASR è¯†åˆ« (ä¼˜å…ˆ FunASRï¼Œå¤‡ç”¨ Whisper)
        asr_type = None
        if os.path.exists(VENV_PYTHON):
            success, asr_type = transcribe_with_funasr(audio_path, json_path)
        
        if not asr_type:
            if transcribe_with_whisper(audio_path, json_path):
                asr_type = "whisper"
        
        if not asr_type:
            print("âŒ ASR è¯†åˆ«å¤±è´¥")
            return
        
        print(f"\nâœ… ä½¿ç”¨ {asr_type.upper()} è¯†åˆ«")
        
        # 3. åŠ è½½ç»“æœ
        segments = load_asr_result(json_path, asr_type)
        print(f"ğŸ“Š åŸå§‹ç‰‡æ®µ: {len(segments)}")
        
        # 4. åˆå¹¶çŸ­ç‰‡æ®µ
        segments = merge_segments(segments)
        print(f"ğŸ“Š åˆå¹¶å: {len(segments)}")
        
        # 5. ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¼˜åŒ–
        segments = contextual_llm_optimize(segments)
        
        # 6. æ˜¾ç¤ºå¯¹æ¯”
        show_comparison(segments)
        
        # 7. ç”Ÿæˆ SRT
        generate_srt(segments, OUTPUT_SRT)
    
    print(f"\n{'=' * 70}")
    print("âœ… å­—å¹•ç”Ÿæˆå®Œæˆ!")
    print(f"{'=' * 70}")
    print(f"è¾“å‡º: {OUTPUT_SRT}")

if __name__ == "__main__":
    main()
